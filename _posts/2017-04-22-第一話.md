---
layout: post
title: Adversarial Generator-Encoder Networks [arXiv:1704.02304]
category: 論文
tags:
- GAN
excerpt_separator: <!--more-->
---

## 第一話

- [Adversarial Generator-Encoder Networks](https://arxiv.org/abs/1704.02304)を読んだ時の話

<!--more-->

## 挨拶
G : 今週のヤンジャンは青山くんが風邪を引いていましたね。どうもguguchiです。

M : 今週のヤンジャンまだ買ってません。帰りに買います。masoです。

G : 今週は[Adversarial Generator-Encoder Networks](https://arxiv.org/abs/1704.02304)（以下、AGE）を読んでいきたいと思います。

リンクは後で修正します。

## 会話

G : まず概要について説明しますね。AGEはadversarial traingを使ってencoderとgeneratorを学習するという論文です。gをgenerator、eをencoderとすると、目標はgとeをadversarial trainingによって訓練する手法です。

$$ \max_e \min_g V(g,e) = KL [e(g(Z)) | e(X) ] $$

M : gとeをバトらせるんだよね

G：僕がよく分からなかったのは、なんでencoderについてmax取ってるかって所です。

M：２ぺージを見たら" Below, we show how to design an adversarial game between e and g that ensures the alignment of g(Z) = X in the data space, while only evaluating divergences in the latent space."って書いてあるね。目標は、潜在変数空間で二つの分布が最も離れるようにencoderを学習させるんですよね

G:いやそれはいいですけど、max minの順番はおかしくないですか？

M：僕もよく分からないです。最大最小不等式っていうのがありますよね。

$$\max_{z \in Z} \min_{w \in W} f(z,w) \leq \min_{w \in W} \max_{z \in Z} f(z,w)$$

これひっくり返すのって問題起こりそうですよね。でもアルゴリズム的には誰も気にしてませんですよね。交互にアップデートするし。

G:ひっくり返すのってやばいですよね。普通みんなmin maxでやってて、例えばGANだと

$$\min_G \max_D E_q[\log D(x)] + E_p[\log (1- D((Z))) ] := V(G,D) $$

こういう目的関数になっています。毎回やってるのは真の分布と生成モデルを最も離すような「距離」をdiscrimantorで学習して、それに基づいて生成モデルを真の分布に近付けるってことです。最終目標はV(G,D)=0にすることです。

M:100同意っすよ。このmin maxってベクトル空間のinfinity norm最小化に似てますよね。

$$ d_{\infty}(f,g) = | f - g |{\infty} = \sup{x} {| f(x) - g(x) | } ~~~~ f, g \in V$$

qがベクトルでFがベクトル空間だとしたら、sup








